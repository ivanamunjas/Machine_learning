{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ucitavanje podataka\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data = pd.read_csv(\"multiclass_data.csv\", header = None)\n",
    "data.head()\n",
    "\n",
    "X = np.array(data.loc[:, 0:4])\n",
    "y = np.array(data.loc[:, 5])\n",
    "\n",
    "X = (X - X.mean())/X.std()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_classifier:\n",
    "    \n",
    "    def softmaxEquation(X, theta):\n",
    "            scores = X.dot(theta)\n",
    "            prob = (np.exp(scores).T / np.sum(np.exp(scores), axis=1)).T\n",
    "            return prob    \n",
    "\n",
    "    def fit(self, X, y, iterations, alpha, labels, batch_size, theta=None):\n",
    "        if theta is None:\n",
    "            self.theta = np.zeros((X.shape[1], labels))\n",
    "        else:\n",
    "            slef.theta = theta\n",
    "            \n",
    "        M = len(y)\n",
    "        num_batches = np.ceil(M/batch_size).astype(int)\n",
    "\n",
    "        for iter_ in range(iterations):\n",
    "            for k in range(num_batches-1):\n",
    "                up_lim = (k+1)*batch_size\n",
    "                if up_lim >= M:\n",
    "                    up_lim = M-1\n",
    "\n",
    "                grads = np.zeros(self.theta.shape)\n",
    "                X_mini = X[k*batch_size:up_lim, :]\n",
    "                y_mini = y[k*batch_size:up_lim]\n",
    "\n",
    "                for i in range(labels):\n",
    "                    p = np.exp(X_mini.dot(self.theta[:, i]))/np.sum(np.exp(X_mini.dot(self.theta)), axis=1)\n",
    "                    y_i = (y_mini == i).astype(int)\n",
    "                    grads[:, i] = X_mini.T.dot(y_i - p)/batch_size\n",
    "\n",
    "                self.theta = self.theta + alpha*grads\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return np.argmax(softmaxEquation(X, self.theta), axis=1)\n",
    "\n",
    "    def accuracy_metric(self, y_pred, y_test):\n",
    "        correct = 0\n",
    "        for i in range(len(y_test)):\n",
    "            if y_test[i] == y_pred[i]:\n",
    "                correct += 1\n",
    "        return correct/float(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tacnost na trenirajucem skupu je:  0.8571428571428571\n",
      "Tacnost na testirajucem skupu je:  0.8813559322033898\n"
     ]
    }
   ],
   "source": [
    "softmax_clf = Softmax_classifier()\n",
    "softmax_clf.fit(X_train, y_train, iterations=10000, alpha=0.5, labels=3, batch_size = 20)\n",
    "\n",
    "y_train_pred = softmax_clf.predict(X_train)\n",
    "y_pred = softmax_clf.predict(X_test)\n",
    "\n",
    "print(\"Tacnost na trenirajucem skupu je: \", softmax_clf.accuracy_metric(y_train_pred, y_train))\n",
    "print(\"Tacnost na testirajucem skupu je: \", softmax_clf.accuracy_metric(y_pred, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
